{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GMDL212_HW5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LemHg46j2cZd"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f4UQRZDBVhh"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "# Clear all tensorboards from previous runs.\n",
        "!rm -rf ./runs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moTeLdF3BuDo"
      },
      "source": [
        "# Exercise 1.\n",
        "\n",
        "batch_size = 64\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "# import data for training purposes.\n",
        "full_train_set = torchvision.datasets.SVHN(root='./root', split='train', download=True, transform=transform)\n",
        "# split data training, 80% training, 20% validation.\n",
        "train_size = int(0.8 * len(full_train_set))\n",
        "validation_size = len(full_train_set) - train_size\n",
        "train_set, validation_set = torch.utils.data.random_split(full_train_set, [train_size, validation_size])\n",
        "# craets dataloader for train data.\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# import and loads data for testing purposes.\n",
        "test_set = torchvision.datasets.SVHN(root='./root', split='test', download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gMKWJX9UxvA"
      },
      "source": [
        "# Exercise 1 - checking that the data has been loaded correctly\n",
        "\n",
        "# choose from train_loader, validation_loader, test_loader\n",
        "data_set_checker = train_loader\n",
        "\n",
        "data_iter = iter(data_set_checker)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "# text style\n",
        "BOLD = '\\033[1m'\n",
        "END = '\\033[0m'\n",
        "\n",
        "print(BOLD+\"information about Batch size and images sizes: \"+END, images.shape)\n",
        "print(BOLD+\"size of label array: \"+END,labels.shape)\n",
        "print(BOLD+\"labels for example: \"+END, labels)\n",
        "# random_img = np.random.seed(data_set_checker)\n",
        "# print(\"random image from data set: \")\n",
        "# plt.imshow(random_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf4nAe1Am0iJ"
      },
      "source": [
        "i = 40\n",
        "# print(images[i].shape)\n",
        "# print(images[i].numpy())\n",
        "img = images[i].permute(1,2,0).numpy()\n",
        "# print(img.shape)\n",
        "# print(img)\n",
        "plt.imshow(img)\n",
        "print(\"the label is: \", labels[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HheGbj8Ztj8I"
      },
      "source": [
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "\n",
        "for i in range(1, num_of_images+1):\n",
        "  plt.subplot(6, 10, i)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(images[i].squeeze().permute(1,2,0), cmap=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izdcMiTR5TyS"
      },
      "source": [
        "# Exercise 2 - Fully Connected NN\n",
        "\n",
        "input_size = 32 * 32 * 3\n",
        "output_size = 10\n",
        "\n",
        "class FC_Net(nn.Module):\n",
        "    def __init__(self, hidden_layer_size_1, hidden_layer_size_2):\n",
        "      super(FC_Net, self).__init__()\n",
        "      self.L1 = nn.Linear(input_size, hidden_layer_size_1)\n",
        "      self.L2 = nn.Linear(hidden_layer_size_1, hidden_layer_size_2)\n",
        "      self.L3 = nn.Linear(hidden_layer_size_2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Flatten out the image before processing.\n",
        "      x = x.view(x.shape[0], -1)\n",
        "      x = self.L1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.L2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.L3(x)\n",
        "      \n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg98oi015UkF"
      },
      "source": [
        "# Exercise 2 - Convolutional NN.\n",
        "\n",
        "class Conv_Net(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "      super(Conv_Net, self).__init__()\n",
        "      self.L1 = nn.Conv2d(3, 10, kernel_size, padding=1, stride=1)\n",
        "      self.L2 = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "      self.L3 = nn.Conv2d(10, 20, kernel_size, padding=1, stride=1)\n",
        "      self.L4 = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "      self.L5 = nn.Linear(20*((32//4)**2), L2)\n",
        "      self.L6 = nn.Linear(L2, L3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.L1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.L2(x)\n",
        "      x = self.L3(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.L4(x)\n",
        "      x = x.view(x.shape[0], -1)\n",
        "      x = self.L5(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.L6(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxbnu2CS8p3y"
      },
      "source": [
        "# Exercise 3 - the train function.\n",
        "\n",
        "epochs = 30\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(net, optimizer, criterion, epochs, title):\n",
        "  loss_board = SummaryWriter(f'runs/{title}_losses')\n",
        "  acc_board = SummaryWriter(f'runs/{title}_accs')\n",
        "  for epoch in range(epochs):\n",
        "    print(f'epoch: {epoch+1}/{epochs}\\n{\"-\"*10}')\n",
        "    for phase in [\"train\", \"validate\"]:\n",
        "      # You can replace \"trainloader\" and \"validloader\" with whatever you name the loaders in exercise 1.\n",
        "      loader = trainloader if phase == \"train\" else validloader\n",
        "\n",
        "      for inputs, labels in loader:\n",
        "        # Implement the actual training here. Make sure that when phase == \"validation\" the network doesn't actually learn.\n",
        "        # I took care of logging accuracy so you see how tensorboard works. You still need to log losses in loss_board though.\n",
        "\n",
        "        # Logging accuracy on each epoch.\n",
        "        # This line uses a field \"outputs\" which doesn't exist yet. This is supposed to be what you name the output of the forward pass.\n",
        "        accuracy = (torch.Tensor(list(map(lambda w: torch.argmax(w), outputs))) == labels).float().sum() / batch_size\n",
        "        acc_board.add_scalar(f'{title}_{phase}_acc', accuracy, epoch)\n",
        "  loss_board.flush()\n",
        "  loss_board.close()\n",
        "  acc_board.flush()\n",
        "  acc_board.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA8C-leb_efG"
      },
      "source": [
        "# Exercise 4 - FC Net with hidden layer sizes 512 and 256.\n",
        "\n",
        "fc_512_256 = FC_Net(512, 256)\n",
        "fc_512_256_optimizer = optim.Adam(fc_512_256.parameters(), lr=learning_rate)\n",
        "train(fcnn, fc_512_256_optimizer, criterion, epochs, \"FNN_512_256\")\n",
        "\n",
        "%tensorboard --logdir=runs/FNN_512_256_losses\n",
        "%tensorboard --logdir=runs/FNN_512_256_accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoSZf0U8AVwE"
      },
      "source": [
        "# Exercise 4 - FC Net with hidden layer sizes 64 and 32.\n",
        "\n",
        "fc_64_32 = FC_Net(64, 32)\n",
        "fc_64_32_optimizer = optim.Adam(fc_64_32.parameters(), lr=learning_rate)\n",
        "train(fcnn, fc_64_32_optimizer, criterion, epochs, \"FNN_64_32\")\n",
        "\n",
        "%tensorboard --logdir=runs/FNN_64_32_losses\n",
        "%tensorboard --logdir=runs/FNN_64_32_accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YBPj_wCAkFC"
      },
      "source": [
        "# Exercise 4 - CNN with kernel size of 10.\n",
        "\n",
        "cnn_10 = Conv_Net(10)\n",
        "cnn_10_optimizer = optim.Adam(cnn_10.parameters(), lr=learning_rate)\n",
        "train(fcnn, cnn_10_optimizer, criterion, epochs, \"CN_10\")\n",
        "\n",
        "%tensorboard --logdir=runs/CNN_10_losses\n",
        "%tensorboard --logdir=runs/CNN_10_accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXLVy5OkAj3M"
      },
      "source": [
        "# Exercise 4 - CNN with kernel size of 1.\n",
        "\n",
        "cnn_1 = Conv_Net(1)\n",
        "cnn_1_optimizer = optim.Adam(cnn_1.parameters(), lr=learning_rate)\n",
        "train(fcnn, cnn_1_optimizer, criterion, epochs, \"CN_1\")\n",
        "\n",
        "%tensorboard --logdir=runs/CNN_1_losses\n",
        "%tensorboard --logdir=runs/CNN_1_accs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}